{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import PRData\n",
    "import traceback\n",
    "import watson_developer_cloud\n",
    "import watson_developer_cloud.natural_language_understanding.features.v1 as features\n",
    "\n",
    "\n",
    "#Credentials for access to Watson\n",
    "credentials = {\n",
    "  \"url\": \"https://gateway.watsonplatform.net/natural-language-understanding/api\",\n",
    "  \"username\": \"fba7b9c0-abbb-4d30-985d-0729614689b9\",\n",
    "  \"password\": \"1I4nEsfDEUMs\"\n",
    "}\n",
    "\n",
    "#Headers for urllib2 in use at process_url function\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8',\n",
    "       'Connection': 'keep-alive'}\n",
    "\n",
    "\n",
    "nlu = watson_developer_cloud.NaturalLanguageUnderstandingV1(version='2017-02-27',\n",
    "                                                            username=credentials['username'],\n",
    "                                                            password=credentials['password'])\n",
    "\n",
    "\n",
    "####################\n",
    "# Functions I am using in this transformation file, consider implications of these, their naming, and location\n",
    "\n",
    "def find_uniques(input_list):\n",
    "    \"\"\"This function takes in an input_list, this is assumed to have duplicates,\n",
    "    and outputs a list that is unique and has beginning and \n",
    "    trailing spaces removed\"\"\"\n",
    "    input_list = input_list.tolist()\n",
    "    uniques = []\n",
    "    for l in input_list:\n",
    "        temp = l.split(',')\n",
    "        for t in temp:\n",
    "            uniques.append(t.lstrip(' ').rstrip(' '))\n",
    "    return uniques\n",
    "\n",
    "\n",
    "def process_response(watson_response):\n",
    "    # Here I am keeping what I need defined to this function. Consider this choice architecturally.\n",
    "    text = []\n",
    "    relevance = []\n",
    "\n",
    "    for key in watson_response['entities']:\n",
    "        text.append(key['text'])\n",
    "        relevance.append(key['relevance'])   \n",
    "    data = {'relevance':relevance,'text':text}\n",
    "    dataframe = pd.DataFrame(data)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "\n",
    "# Tag the dataframe, i.e. create columns 'Jurisdiction_autotag' and 'Member_autotag'\n",
    "def watson_tagging(dataframe):\n",
    "    \"\"\"Processes the dataframe from PRData.data_pull() and returns the dataframe\n",
    "    with two additional columns Jurisdiction_autotag & Member_autotag.\"\"\"\n",
    "    for index, row in dataframe.iterrows():\n",
    "        url = dataframe.ix[index]['URL'].lstrip().rstrip()\n",
    "        members_in_text = []\n",
    "        juris_in_text = []\n",
    "\n",
    "        try:\n",
    "            \n",
    "            print url\n",
    "            w_response = nlu.analyze(url=url,features=[features.Entities()])\n",
    "            entities = process_response(w_response)\n",
    "            print entities['text']\n",
    "            \n",
    "            for member in unique_members:\n",
    "                for item in entities['text']:\n",
    "                    if member in item:\n",
    "                        members_in_text.append(member)\n",
    "\n",
    "            for jurisdiction in unique_juris:\n",
    "                for item in entities['text']:\n",
    "                    if jurisdiction in item:\n",
    "                        juris_in_text.append(jurisdiction)\n",
    "                        \n",
    "        except Exception:\n",
    "            print(traceback.format_exc())\n",
    "            print \"Could not process: %s\" % url\n",
    "\n",
    "        # turn lists of jurisdictions and members into comma-separated string\n",
    "        juris_in_text = ', '.join(juris_in_text)\n",
    "        members_in_text = ', '.join(members_in_text)\n",
    "\n",
    "        # If they exist, then assign the string or '-' for nothing\n",
    "        if juris_in_text is not None:\n",
    "            dataframe.ix[index]['Jurisdiction_autotag'] = juris_in_text\n",
    "        else:\n",
    "            dataframe.ix[index]['Jurisdiction_autotag'] = '-'\n",
    "\n",
    "        # If they exist, then assign the string or '-' for nothing\n",
    "        if members_in_text is not None:\n",
    "            dataframe.ix[index]['Member_autotag'] = members_in_text\n",
    "        else:\n",
    "            dataframe.ix[index]['Member_autotag'] = '-'\n",
    "        \n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "# Process the current data down and build what I need from it\n",
    "\n",
    "current_month = 'July 2016' #MOVE TO CONFIG\n",
    "\n",
    "data = PRData.data_pull()\n",
    "current_data = data[data['DATE'] == current_month]\n",
    "\n",
    "# This section is used to process all the data to end up with unique lists of jurisdictions & member\n",
    "# this has to be ran before the next section. This needs to be moved as it's more of a helper function\n",
    "# The data needs to be output and preserved and then called into this script\n",
    "juris = data['Jurisdictions Mentioned'].unique()\n",
    "members = data['Members Mentioned']\n",
    "\n",
    "juris = find_uniques(juris)\n",
    "members = find_uniques(members)\n",
    "\n",
    "unique_juris = list(set(juris))\n",
    "unique_juris = filter(None,unique_juris)\n",
    "unique_members = list(set(members))\n",
    "unique_members = filter(None, unique_members)\n",
    "\n",
    "##########\n",
    "# Using what is previous created, get started with watson request and handling\n",
    "# Response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(629, 13)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taggable_content = data[~data['URL'].str.contains('images')]\n",
    "taggable_content = taggable_content[~taggable_content['TYPE'].str.contains('vision')]\n",
    "taggable_content.shape\n",
    "\n",
    "tagged_content = watson_tagging(taggable_content.head(3))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
